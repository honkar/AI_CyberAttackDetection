{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"plotlib_helper.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"-DH9gsPLd4YJ"},"source":["## Model Visualization Helper Functions"]},{"cell_type":"code","metadata":{"id":"vTNu9RJf2Y9Y","executionInfo":{"status":"ok","timestamp":1601493809904,"user_tz":420,"elapsed":1365,"user":{"displayName":"Gargi P","photoUrl":"","userId":"12090553606135564997"}}},"source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","from sklearn import metrics\n","from sklearn.metrics import roc_curve, auc\n","\n","# Plot a confusion matrix.\n","# cm is the confusion matrix, names are the names of the classes.\n","def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(names))\n","    plt.xticks(tick_marks, names, rotation=45)\n","    plt.yticks(tick_marks, names)\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","    \n","\n","# Plot an ROC. pred - the predictions, y - the expected output.\n","def plot_roc(pred,y):\n","    fpr, tpr, thresholds = roc_curve(y, pred)\n","    roc_auc = auc(fpr, tpr)\n","\n","    plt.figure()\n","    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n","    plt.plot([0, 1], [0, 1], 'k--')\n","    plt.xlim([0.0, 1.0])\n","    plt.ylim([0.0, 1.05])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title('Receiver Operating Characteristic (ROC)')\n","    plt.legend(loc=\"lower right\")\n","    plt.show()"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"FWGzN1xsc-Hw","executionInfo":{"status":"ok","timestamp":1601493810261,"user_tz":420,"elapsed":1698,"user":{"displayName":"Gargi P","photoUrl":"","userId":"12090553606135564997"}}},"source":["import numpy as np\n","from sklearn import metrics\n","from sklearn import svm, datasets\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix, classification_report\n","\n","# Input : Predicitions, Ground truth (y_test), Labels for plotting graph, title for graph\n","def performance_metrics(pred, y_test, labels, title, plotROC=True, isNeuralNet=True):\n","  \n","  if (isNeuralNet):\n","    y_true = np.argmax(y_test,axis=1)\n","  else:\n","    y_true = y_test\n","\n","\n","  print(title)\n","  print(\"---------------------------------------\")\n","\n","  accuracy_score = metrics.accuracy_score(y_true, pred)\n","  print(\"Accuracy score: {}\".format(accuracy_score))\n","\n","  precision_score = metrics.precision_score(y_true, pred, average=\"weighted\")\n","  print(\"Precision score: {}\".format(precision_score))\n","\n","  recall_score = metrics.recall_score(y_true, pred, average=\"weighted\")\n","  print(\"Recall score: {}\".format(recall_score))\n","\n","  f1_score = metrics.f1_score(y_true, pred, average=\"weighted\")\n","  print(\"F1 score: {}\".format(f1_score))\n","\n","  print()\n","  print()\n","  # Compute confusion matrix\n","  cm = confusion_matrix(y_true, pred)\n","  print(cm)\n","\n","  print()\n","  print()\n","  print('Plotting confusion matrix')\n","\n","  plt.figure()\n","  plot_confusion_matrix(cm, labels)\n","  plt.show()\n","\n","  print()\n","  print()\n","  print(classification_report(y_true, pred))\n","\n","  print()\n","  # check if binary or multiclass classification plotROC = False for multiclass\n","  if(plotROC):\n","    plot_roc(pred,y_true)"],"execution_count":2,"outputs":[]}]}